{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project2_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAbo6YFI4G3v"
      },
      "source": [
        "\n",
        "## imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS1hwh-Q4AgO",
        "outputId": "13b01918-47c3-4e24-947e-0b921c326cb3"
      },
      "source": [
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import Sequential, optimizers\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, LeakyReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != \"/device:GPU:0\":\n",
        "  raise SystemError(\"GPU device not found\")\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIF1o1kR3gOg"
      },
      "source": [
        "## Initialize here input variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCm0m2x6_Im6"
      },
      "source": [
        "conv_layers = 3\n",
        "kernel_sizes = [(7, 7), (5, 5), (3, 3)]\n",
        "filters = [8, 16, 32]\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "third_maxpool = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0evH9T1k4Nsu"
      },
      "source": [
        "## load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY3XdwBN5heP"
      },
      "source": [
        "def parse_dataset(filepath):\n",
        "    \"\"\" function used to parse the data of a dataset \"\"\"\n",
        "\n",
        "    # open the dataset\n",
        "    with open(filepath, \"rb\") as dataset:\n",
        "        # read the magic number and the number of images\n",
        "        magic_number, number_of_images = struct.unpack(\">II\", dataset.read(8))\n",
        "        # read the number of rows and number of columns per image\n",
        "        rows, columns = struct.unpack(\">II\", dataset.read(8))\n",
        "        # now read the rest of the file using numpy.fromfile()\n",
        "        images = np.fromfile(dataset, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
        "        # reshape so that the final shape is (number_of_images, rows, columns)\n",
        "        images = images.reshape((number_of_images, rows, columns))\n",
        "\n",
        "    # return the images\n",
        "    return images\n",
        "\n",
        "\n",
        "def parse_labelset(filepath):\n",
        "    \"\"\" function used to parse the data of a labelset \"\"\"\n",
        "\n",
        "    # open the file\n",
        "    with open(filepath, \"rb\") as labelset:\n",
        "        # read the magic number and the number of labels\n",
        "        magic_number, number_of_labels = struct.unpack(\">II\", labelset.read(8))\n",
        "        # now read the rest of the file using numpy.fromfile()\n",
        "        labels = np.fromfile(labelset, dtype=np.dtype(np.uint8).newbyteorder(\">\"))\n",
        "\n",
        "    # return the labels\n",
        "    return labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ2zjJsr4PAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b147979-c312-45f4-8a3d-6185b59670ac"
      },
      "source": [
        "# EDIT THE PATHS OF THE DATASETS HERE\n",
        "train_images_path = os.path.join(\".\", \"drive\", \"My Drive\", \"Colab Notebooks\", \"Project\", \"Project2\", \"Dataset\", \"train-images-idx3-ubyte\")\n",
        "train_labels_path = os.path.join(\".\", \"drive\", \"My Drive\", \"Colab Notebooks\", \"Project\", \"Project2\", \"Dataset\", \"train-labels-idx1-ubyte\")\n",
        "\n",
        "test_images_path = os.path.join(\".\", \"drive\", \"My Drive\", \"Colab Notebooks\", \"Project\", \"Project2\", \"Dataset\", \"t10k-images-idx3-ubyte\")\n",
        "test_labels_path = os.path.join(\".\", \"drive\", \"My Drive\", \"Colab Notebooks\", \"Project\", \"Project2\", \"Dataset\", \"t10k-labels-idx1-ubyte\")\n",
        "\n",
        "\n",
        "# LOAD THE DATASETS HERE\n",
        "X_train = parse_dataset(train_images_path)\n",
        "y_train = parse_labelset(train_labels_path)\n",
        "\n",
        "X_test = parse_dataset(test_images_path)\n",
        "y_test = parse_labelset(test_labels_path)\n",
        "\n",
        "# GET USEFUL VARIABLES\n",
        "rows = X_train.shape[1]\n",
        "columns = X_train.shape[2]\n",
        "\n",
        "# GET VALIDATION DATASET FROM TRAINING SET\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=13, shuffle=True)\n",
        "\n",
        "# RESHAPE SO THAT THE FINAL SHAPE IS (number_of_images, rows, columns, 1)\n",
        "X_train = X_train.reshape(-1, rows, columns, 1)\n",
        "X_val = X_val.reshape(-1, rows, columns, 1)\n",
        "X_test = X_test.reshape(-1, rows, columns, 1)\n",
        "\n",
        "# SCALE INPUT\n",
        "X_train = X_train / 255.\n",
        "X_val = X_val / 255.\n",
        "X_test = X_test / 255.\n",
        "\n",
        "\n",
        "# PRINTS TO MAKE SURE\n",
        "print(\"X_train.shape = {}\".format(X_train.shape))\n",
        "print(\"y_train.shape = {}\".format(y_train.shape))\n",
        "print()\n",
        "print(\"X_val.shape = {}\".format(X_val.shape))\n",
        "print(\"y_val.shape = {}\".format(y_val.shape))\n",
        "print()\n",
        "print(\"X_test.shape = {}\".format(X_test.shape))\n",
        "print(\"y_test.shape = {}\".format(y_test.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train.shape = (51000, 28, 28, 1)\n",
            "y_train.shape = (51000,)\n",
            "\n",
            "X_val.shape = (9000, 28, 28, 1)\n",
            "y_val.shape = (9000,)\n",
            "\n",
            "X_test.shape = (10000, 28, 28, 1)\n",
            "y_test.shape = (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnnBHqHC-yAC"
      },
      "source": [
        "## print utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdoVf6y-9f1B"
      },
      "source": [
        "def print_image(image, rows, columns):\n",
        "    \"\"\" function used to print an image to the console \"\"\"\n",
        "\n",
        "    # for each row of the image\n",
        "    for i in range(rows):\n",
        "        # for each column\n",
        "        for j in range(columns):\n",
        "            # print the value at the coordinate (i, j) if it is not 0\n",
        "            if image[i, j] != 0:\n",
        "                print(\"{:.3f}\".format(image[i, j, 0]), end=\"\")\n",
        "            else:\n",
        "                print(\"   \", end=\"\")\n",
        "        # print a newline since the row has finished\n",
        "        print()\n",
        "    print()\n",
        "\n",
        "\n",
        "def plot_image(image):\n",
        "    \"\"\" fuction used to plot an image using matplotlib \"\"\"\n",
        "\n",
        "    # plot and show the image\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "id": "7C_li9vc-271",
        "outputId": "7ba4e064-8312-428f-f11a-e637aeaf204f"
      },
      "source": [
        "print_image(X_train[69], 28, 28)\n",
        "plot_image(X_train[69, :, :, 0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                    \n",
            "                                                                                    \n",
            "                                                                                    \n",
            "                                                                                    \n",
            "                                                                                    \n",
            "                                       0.2000.9840.231                                    \n",
            "                                       0.4160.9920.639                                    \n",
            "                                       0.3730.9920.882                                    \n",
            "                                       0.2900.9920.9880.224                                 \n",
            "                                       0.1490.9760.9960.286                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                          0.7760.9960.286                                 \n",
            "                                          0.6390.9960.286                                 \n",
            "                                          0.6390.9960.286                                 \n",
            "                                          0.9651.0000.290                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                          0.9610.9960.286                                 \n",
            "                                       0.1530.9760.9690.047                                 \n",
            "                                       0.2900.9920.682                                    \n",
            "                                       0.5800.9920.557                                    \n",
            "                                       0.6080.9920.322                                    \n",
            "                                       0.6080.9920.322                                    \n",
            "                                                                                    \n",
            "                                                                                    \n",
            "                                                                                    \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsUhhRNzS37u"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlBQf0HV319f"
      },
      "source": [
        "## functions to create autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s9JhumS3zzm"
      },
      "source": [
        "def create_encoder(rows, columns, conv_layers, kernel_sizes, filters, use_third_max_pooling=True,\n",
        "                   use_leaky_relu=False, leaky_relu_alpha=0.15):\n",
        "    \"\"\"\n",
        "    Function used to create the encoder part of the autoencoder. The architecture follows the\n",
        "    following rules:\n",
        "\n",
        "    1) Every Convolutional Layer is followed by a Batch Batch Normalization.\n",
        "\n",
        "    2) The First 3 Convolutional Layers also have a Max Pooling at the end. The first 2 Max Pooling\n",
        "       layers have a pool size of (2, 2), while the third (if used) has a pool size of (7, 7). If\n",
        "       less than 3 Convolutional Layers are available, then fewer Max Pooling layers are used.\n",
        "\n",
        "    3) The activation function used in the Convolutional Layers is ReLU, but it can be changed to\n",
        "       using Leaky ReLU just by setting the parameter \"use_leaky_relu\" to True and picking an alpha.\n",
        "\n",
        "    4) Padding in Convolutions is always \"same\", that is, the output image from the convolution has\n",
        "       the same shape as the input. Only the Max Pooling layers reduce the dimension of the images.\n",
        "    \"\"\"\n",
        "\n",
        "    # define the input\n",
        "    input = Input(shape=(rows, columns, 1))\n",
        "    x = input\n",
        "\n",
        "    # place the Convolutional-BatchNormalization-[MaxPooling] sets of layers\n",
        "    for layer in range(conv_layers):\n",
        "\n",
        "        # determine whether to use ReLU or Leaky ReLU\n",
        "        if not use_leaky_relu:\n",
        "            x = Conv2D(filters=filters[layer], kernel_size=kernel_sizes[layer], activation=\"relu\",\n",
        "                       padding=\"same\")(x)\n",
        "        else:\n",
        "            x = Conv2D(filters=filters[layer], kernel_size=kernel_sizes[layer], activation=\"linear\",\n",
        "                       padding=\"same\")(x)\n",
        "            x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "\n",
        "        # perform batch normalization\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # if we are placing a the 3rd layer and MaxPooling should be placed, do it\n",
        "        if layer == 2 and use_third_max_pooling:\n",
        "            x = MaxPooling2D(pool_size=(7, 7))(x)\n",
        "        # if we are in the placing of the first 2 layers, place also a MaxPooling\n",
        "        if layer < 2:\n",
        "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # create the encoder part and return it\n",
        "    encoder = Model(input, x, name=\"encoder\")\n",
        "    return encoder\n",
        "\n",
        "\n",
        "def create_decoder(rows, columns, conv_layers, kernel_sizes, filters, use_third_max_pooling=True,\n",
        "                   use_leaky_relu=False, leaky_relu_alpha=0.15):\n",
        "    \"\"\"\n",
        "    Function used to create the decoder part of the Autoencoder. The architecture is basically the\n",
        "    \"mirrored\" architecture of the encoder.\n",
        "    \"\"\"\n",
        "\n",
        "    # define the input\n",
        "    factor = min(conv_layers, 2) * 2\n",
        "    if conv_layers >= 3 and use_third_max_pooling:\n",
        "        factor *= 7\n",
        "    input_rows = rows // factor\n",
        "    input_columns = columns // factor\n",
        "    input = Input(shape=(input_rows, input_columns, filters[-1]))\n",
        "    x = input\n",
        "\n",
        "    # place the Convolutional-BatchNormalization-[MaxPooling] sets of layers in a mirrored way\n",
        "    last_layer = len(filters) - 1\n",
        "    for layer in range(last_layer, -1, -1):\n",
        "\n",
        "        # determine whether to use Leaky ReLU or normal ReLU\n",
        "        if not use_leaky_relu:\n",
        "            x = Conv2D(filters=filters[layer], kernel_size=kernel_sizes[layer], activation=\"relu\",\n",
        "                       padding=\"same\")(x)\n",
        "        else:\n",
        "            x = Conv2D(filters=filters[-1], kernel_size=kernel_sizes[-1], activation=\"linear\",\n",
        "                       padding=\"same\")(input)\n",
        "            x = LeakyReLU(alpha=leaky_relu_alpha)(x)\n",
        "\n",
        "        # add batch normalization\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        # if we are in the third layer and a 3rd Max Pooling was placed, place an UpSampling\n",
        "        if layer == 2 and use_third_max_pooling:\n",
        "            x = UpSampling2D(size=(7, 7))(x)\n",
        "        # if we are in the first 2 layers, place an UpSampling\n",
        "        if layer < 2:\n",
        "            x = UpSampling2D(size=(2, 2))(x)\n",
        "\n",
        "    # do the final convolution to convert the image to the normal shape\n",
        "    x = Conv2D(filters=1, kernel_size=kernel_sizes[-1], activation=\"sigmoid\", padding=\"same\")(x)\n",
        "\n",
        "    # create the decoder part and return it\n",
        "    decoder = Model(input, x, name=\"decoder\")\n",
        "    return decoder\n",
        "\n",
        "\n",
        "def create_autoencoder(rows, columns, encoder, decoder):\n",
        "    \"\"\"\n",
        "    Function that given the encoder part and the decoder part of an autoencoder, creates a \"Model\"\n",
        "    (Keras object) that represents an autoencoder.\n",
        "    \"\"\"\n",
        "\n",
        "    # define the input\n",
        "    input = Input(shape=(rows, columns, 1))\n",
        "\n",
        "    # pass the input through the encoder\n",
        "    x = encoder(input)\n",
        "\n",
        "    # pass then the result through the decoder\n",
        "    x = decoder(x)\n",
        "\n",
        "    # create the model and return it\n",
        "    autoencoder = Model(input, x, name=\"autoencoder\")\n",
        "    return autoencoder"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2f9IFaj4BXs"
      },
      "source": [
        "## create the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94ju0ukn4Cu1",
        "outputId": "a86494d0-bba1-493a-941c-fdaac5b3d4b2"
      },
      "source": [
        "# get the encoder and the decoder\n",
        "encoder = create_encoder(rows, columns, conv_layers, kernel_sizes, filters)\n",
        "decoder = create_decoder(rows, columns, conv_layers, kernel_sizes, filters)\n",
        "\n",
        "# print summaries\n",
        "print(encoder.summary())\n",
        "print(decoder.summary())\n",
        "\n",
        "# get the autoencoder\n",
        "autoencoder = create_autoencoder(rows, columns, encoder, decoder)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 8)         400       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 8)         32        \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 16)        3216      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 32)          4640      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 32)          0         \n",
            "=================================================================\n",
            "Total params: 8,480\n",
            "Trainable params: 8,368\n",
            "Non-trainable params: 112\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1, 1, 32)]        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 32)          9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1, 1, 32)          128       \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 7, 7, 16)          12816     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 8)         6280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 14, 14, 8)         32        \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 28, 28, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         73        \n",
            "=================================================================\n",
            "Total params: 28,641\n",
            "Trainable params: 28,529\n",
            "Non-trainable params: 112\n",
            "_________________________________________________________________\n",
            "None\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder (Functional)         (None, 1, 1, 32)          8480      \n",
            "_________________________________________________________________\n",
            "decoder (Functional)         (None, 28, 28, 1)         28641     \n",
            "=================================================================\n",
            "Total params: 37,121\n",
            "Trainable params: 36,897\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3DRdPkkXIDq"
      },
      "source": [
        "## create a custom callback for when the validation loss plateaus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIhUl-McXM06"
      },
      "source": [
        "# add a callback to reduce learning rate when validation loss plateaus\n",
        "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=1.0/2, patience=4, min_delta=0.005,\n",
        "                              cooldown=0, min_lr=1e-8, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeOCA1gA7DSm"
      },
      "source": [
        "## train the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7iwYj_r4R6g",
        "outputId": "d4c63930-720f-4687-97b0-fa57b511dc4b"
      },
      "source": [
        "# compile and train the autoencoder\n",
        "autoencoder.compile(optimizer=optimizers.Adam(1e-3), loss=\"mse\", metrics=[\"mse\"])\n",
        "history = autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs,\n",
        "                          shuffle=True, validation_data=(X_val, X_val))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1594/1594 [==============================] - 9s 6ms/step - loss: 0.0528 - mse: 0.0528 - val_loss: 0.0342 - val_mse: 0.0342\n",
            "Epoch 2/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0228 - val_mse: 0.0228\n",
            "Epoch 3/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.0192 - val_mse: 0.0192\n",
            "Epoch 4/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.0172 - val_mse: 0.0172\n",
            "Epoch 5/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0182 - val_mse: 0.0182\n",
            "Epoch 6/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0160 - val_mse: 0.0160\n",
            "Epoch 7/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0170 - val_mse: 0.0170\n",
            "Epoch 8/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0159 - val_mse: 0.0159\n",
            "Epoch 9/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0145 - val_mse: 0.0145\n",
            "Epoch 10/10\n",
            "1594/1594 [==============================] - 8s 5ms/step - loss: 0.0161 - mse: 0.0161 - val_loss: 0.0146 - val_mse: 0.0146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3N_0IRap823d"
      },
      "source": [
        "## make a prediction of this image and print it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "uQIo9oSh81_5",
        "outputId": "0c1efd16-7d43-4c5e-c69d-248de53ddc0f"
      },
      "source": [
        "# print(X_test[69].shape)\n",
        "pred = autoencoder.predict(X_test)\n",
        "plot_image(X_test[2001, :, :, 0])\n",
        "plot_image(pred[2001, :, :, 0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n7kAhAc89po"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}